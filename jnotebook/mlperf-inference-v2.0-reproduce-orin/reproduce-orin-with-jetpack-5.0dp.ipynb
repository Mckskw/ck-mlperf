{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPerf Inference v2.0 - Reproducing Orin results with JetPack 5.0.1 DP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [System](#system)\n",
    "1. [Installation](#installation)\n",
    "    1. [Clone the repo](#installation_repo)\n",
    "    1. [Install the dependencies](#installation_deps)\n",
    "    1. [Link the datasets](#installation_datasets)\n",
    "    1. [Download the models](#installation_models)\n",
    "    1. [Build the harness](#installation_harness)\n",
    "1. [ResNet50](#resnet50)\n",
    "    1. [Offline](#resnet50_offline)\n",
    "        1. [Build](#resnet50_offline_build)\n",
    "        1. [Performance](#resnet50_offline_performance)\n",
    "        1. [Accuracy](#resnet50_offline_accuracy)\n",
    "    1. [SingleStream](#resnet50_singlestream)\n",
    "        1. [Build](#resnet50_singlestream_build)\n",
    "        1. [Performance](#resnet50_singlestream_performance)\n",
    "        1. [Accuracy](#resnet50_singlestream_accuracy)\n",
    "    1. [MultiStream](#resnet50_multistream)\n",
    "        1. [Build](#resnet50_multistream_build)\n",
    "        1. [Performance](#resnet50_multistream_performance)\n",
    "        1. [Accuracy](#resnet50_multistream_accuracy)\n",
    "1. [SSD-ResNet34](#ssd-resnet34)\n",
    "    1. [Offline](#ssd-resnet34_offline)\n",
    "        1. [Build](#ssd-resnet34_offline_build)\n",
    "        1. [Performance](#ssd-resnet34_offline_performance)\n",
    "        1. [Accuracy](#ssd-resnet34_offline_accuracy)\n",
    "    1. [SingleStream](#ssd-resnet34_singlestream)\n",
    "        1. [Build](#ssd-resnet34_singlestream_build)\n",
    "        1. [Performance](#ssd-resnet34_singlestream_performance)\n",
    "        1. [Accuracy](#ssd-resnet34_singlestream_accuracy)\n",
    "    1. [MultiStream](#ssd-resnet34_multistream)\n",
    "        1. [Build](#ssd-resnet34_multistream_build)\n",
    "        1. [Performance](#ssd-resnet34_multistream_performance)\n",
    "        1. [Accuracy](#ssd-resnet34_multistream_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"system\"></a>\n",
    "# System: [NVIDIA Orin](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/systems/Orin_TRT.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats: JetPack\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; sudo -H python3 -m pip install jetson-stats -U\n",
    "...\n",
    "Successfully installed jetson-stats-3.1.0\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; jetson_release\n",
    "\n",
    " - NVIDIA Jetson UNKNOWN\n",
    "   * Jetpack UNKNOWN [L4T 34.1.0]\n",
    "   * NV Power Mode: MAXN - Type: 0\n",
    "   * jetson_stats.service: active\n",
    " - Libraries:\n",
    "   * CUDA: NOT_INSTALLED\n",
    "   * cuDNN: 8.3.2.49\n",
    "   * TensorRT: 8.4.0.9\n",
    "   * Visionworks: NOT_INSTALLED\n",
    "   * OpenCV: 4.5.4 compiled CUDA: NO\n",
    "   * VPI: ii libnvvpi2 2.0.9 arm64 NVIDIA Vision Programming Interface library\n",
    "   * Vulkan: 1.3.203\n",
    "</pre>\n",
    "\n",
    "## OS: Ubuntu 18.04.5 LTS\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; cat /etc/lsb-release\n",
    "DISTRIB_ID=Ubuntu\n",
    "DISTRIB_RELEASE=20.04\n",
    "DISTRIB_CODENAME=focal\n",
    "DISTRIB_DESCRIPTION=&quot;Ubuntu 20.04.4 LTS&quot;\n",
    "</pre>\n",
    "\n",
    "## CPU: 12-core ARMv81 @ 2200 MHz\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; lscpu\n",
    "Architecture:                    aarch64\n",
    "CPU op-mode(s):                  32-bit, 64-bit\n",
    "Byte Order:                      Little Endian\n",
    "CPU(s):                          12\n",
    "On-line CPU(s) list:             0-11\n",
    "Thread(s) per core:              1\n",
    "Core(s) per socket:              4\n",
    "Socket(s):                       3\n",
    "Vendor ID:                       ARM\n",
    "Model:                           1\n",
    "Model name:                      ARMv8 Processor rev 1 (v8l)\n",
    "Stepping:                        r0p1\n",
    "CPU max MHz:                     2201.6001\n",
    "CPU min MHz:                     115.2000\n",
    "BogoMIPS:                        62.50\n",
    "L1d cache:                       768 KiB\n",
    "L1i cache:                       768 KiB\n",
    "L2 cache:                        3 MiB\n",
    "L3 cache:                        6 MiB\n",
    "Vulnerability Itlb multihit:     Not affected\n",
    "Vulnerability L1tf:              Not affected\n",
    "Vulnerability Mds:               Not affected\n",
    "Vulnerability Meltdown:          Not affected\n",
    "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
    "Vulnerability Spectre v1:        Mitigation; __user pointer sanitization\n",
    "Vulnerability Spectre v2:        Not affected\n",
    "Vulnerability Srbds:             Not affected\n",
    "Vulnerability Tsx async abort:   Not affected\n",
    "Flags:                           fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm lrcpc dcpop asimddp uscat ilrcpc flagm\n",
    "</pre>\n",
    "\n",
    "## GPU\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; sudo jetson_clocks\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; sudo jetson_clocks --show\n",
    "SOC family:tegra234  Machine:NVIDIA Orin Jetson-Small Developer Kit\n",
    "Online CPUs: 0-11\n",
    "cpu0: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu1: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu10: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu11: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu2: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu3: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu4: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu5: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu6: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu7: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu8: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu9: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "GPU MinFreq=1300500000 MaxFreq=1300500000 CurrentFreq=1300500000\n",
    "EMC MinFreq=204000000 MaxFreq=3199000000 CurrentFreq=3199000000 FreqOverride=1\n",
    "DLA0_CORE MinFreq=0 MaxFreq=1536000000 CurrentFreq=1536000000\n",
    "DLA0_FALCON MinFreq=0 MaxFreq=832000000 CurrentFreq=832000000\n",
    "DLA1_CORE MinFreq=0 MaxFreq=1536000000 CurrentFreq=1536000000\n",
    "DLA1_FALCON MinFreq=0 MaxFreq=832000000 CurrentFreq=832000000\n",
    "PVA0_VPS0 MinFreq=0 MaxFreq=1152000000 CurrentFreq=1152000000\n",
    "PVA0_AXI MinFreq=0 MaxFreq=832000000 CurrentFreq=832000000\n",
    "FAN Dynamic Speed control=active hwmon3_pwm=88\n",
    "NV Power Mode: MAXN\n",
    "</pre>\n",
    "\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; ck compile program:tool-print-cuda-devices\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; ck run program:tool-print-cuda-devices\n",
    "...\n",
    "GPU Device ID: 0\n",
    "GPU Name: Orin\n",
    "GPU compute capability: 8.7\n",
    "CUDA driver version: 11.4\n",
    "CUDA runtime version: 11.4\n",
    "Global memory: 32110174208\n",
    "Max clock rate: 1300.000000 MHz\n",
    "Total amount of shared memory per block: 49152\n",
    "Total number of registers available per block: 65536\n",
    "Warp size: 32\n",
    "Maximum number of threads per multiprocessor:  1536\n",
    "Maximum number of threads per block: 1024\n",
    "Max dimension size of a thread block X: 1024\n",
    "Max dimension size of a thread block Y: 1024\n",
    "Max dimension size of a thread block Z: 64\n",
    "Max dimension size of a grid size X: 2147483647\n",
    "Max dimension size of a grid size Y: 65535\n",
    "Max dimension size of a grid size Z: 65535\n",
    "</pre>\n",
    "\n",
    "\n",
    "## Disks\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; df -h\n",
    "Filesystem      Size  Used Avail Use% Mounted on\n",
    "/dev/mmcblk0p1   57G   18G   37G  33% /\n",
    "none             15G     0   15G   0% /dev\n",
    "tmpfs            15G   52K   15G   1% /dev/shm\n",
    "tmpfs           3.0G   11M  3.0G   1% /run\n",
    "tmpfs           5.0M  4.0K  5.0M   1% /run/lock\n",
    "tmpfs            15G     0   15G   0% /sys/fs/cgroup\n",
    "/dev/mmcblk1p1  469G   36G  409G   9% /sd\n",
    "tmpfs           3.0G   16K  3.0G   1% /run/user/124\n",
    "tmpfs           3.0G  4.0K  3.0G   1% /run/user/1000\n",
    "tmpfs           3.0G  8.0K  3.0G   1% /run/user/1001\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation\"></a>\n",
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation_repo\"></a>\n",
    "## Clone the v2.0 results repo\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; git clone https://github.com/mlcommons/inference_results_v2.0.git</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation_deps\"></a>\n",
    "## Install the dependencies\n",
    "\n",
    "To [quote](https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure) Azure:\n",
    "> Note that this might take a while, on the order of several hours.\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; chmod +x inference_results_v2.0/closed/Azure/scripts/install_orin_jetson_dependencies.sh\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; time sudo inference_results_v2.0/closed/Azure/scripts/install_orin_jetson_dependencies.sh\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; python3 -m pip install onnx\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation_datasets\"></a>\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; echo 'export MLPERF_SCRATCH_PATH=/datasets/nvidia_scratch' >> $HOME/.bashrc\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; source $HOME/.bashrc\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; mkdir &dollar;MLPERF_SCRATCH_PATH\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; cd &dollar;MLPERF_SCRATCH_PATH\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/nvidia_scratch</b></font>&dollar; mkdir data models preprocessed_data\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/mlperf_scratch_path</b></font>&dollar; ls -la /datasets/nvidia_scratch/\n",
    "total 20\n",
    "drwxrwsr-x  3 anton dvdt 4096 Jan 28 11:10 <font color=\"#268BD2\"><b>.</b></font>\n",
    "drwxrwsr-x 17 root  dvdt 4096 Jan 28 09:53 <font color=\"#268BD2\"><b>..</b></font>\n",
    "lrwxrwxrwx  1 anton dvdt   64 Jan 28 11:10 <font color=\"#2AA198\"><b>data</b></font> \n",
    "drwxrwsr-x  5 anton dvdt 4096 Jan 28 09:54 <font color=\"#268BD2\"><b>models</b></font>\n",
    "lrwxrwxrwx  1 anton dvdt   77 Jan 28 11:10 <font color=\"#2AA198\"><b>preprocessed_data</b></font> \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"download_datasets\"></a>\n",
    "## Download the datasets\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>:/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make download_data BENCHMARKS=\"bert ssd-mobilenet\"\n",
    "\n",
    "<a name=\"installation_models\"></a>\n",
    "## Download the models\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>:/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make download_model BENCHMARKS=\"resnet50 bert ssd-mobilenet ssd-resnet34\"\n",
    "...\n",
    "Finished downloading all the models!\n",
    "</pre>\n",
    "\n",
    "## Preprocess the dataset\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>:/datasets/inference_results_v2.0/closed/Azure</b></font>&dollar; make preprocess_data BENCHMARKS=\"resnet50 bert ssd-mobilenet ssd-resnet34\"\n",
    "</pre>\n",
    "\n",
    "## Build the binaries\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; git diff code/harness/CMakeLists.txt\n",
    "\n",
    "diff --git a/closed/NVIDIA/code/harness/CMakeLists.txt b/closed/NVIDIA/code/harness/CMakeLists.txt\n",
    "index 074c0bc25..b205e7691 100644\n",
    "--- a/closed/NVIDIA/code/harness/CMakeLists.txt\n",
    "+++ b/closed/NVIDIA/code/harness/CMakeLists.txt\n",
    "@@ -503,48 +503,48 @@ else()\n",
    "     )\n",
    "\n",
    "     ######### RNN-T HARNESS ########\n",
    "-    execute_process(COMMAND echo \"Building RNN-T harness...\")\n",
    "+    #    execute_process(COMMAND echo \"Building RNN-T harness...\")\n",
    "\n",
    "-    get_dali_paths(DALI_INCLUDE_DIR DALI_LIB_DIR DALI_LIBRARIES)\n",
    "+    #    get_dali_paths(DALI_INCLUDE_DIR DALI_LIB_DIR DALI_LIBRARIES)\n",
    "\n",
    "-    message(STATUS \"DALI libraries DIR: \" ${DALI_LIB_DIR})\n",
    "-    message(STATUS \"DALI include DIR: \" ${DALI_INCLUDE_DIR})\n",
    "+    #    message(STATUS \"DALI libraries DIR: \" ${DALI_LIB_DIR})\n",
    "+    #    message(STATUS \"DALI include DIR: \" ${DALI_INCLUDE_DIR})\n",
    "\n",
    "-    message(STATUS \"DALI linked libraries: \" ${DALI_LIBRARIES})\n",
    "+    #    message(STATUS \"DALI linked libraries: \" ${DALI_LIBRARIES})\n",
    "\n",
    "-    add_executable(harness_rnnt\n",
    "-        harness_rnnt/main_rnnt.cc\n",
    "-        harness_rnnt/rnnt_kernels.cu\n",
    "-        common/logger.cpp\n",
    "-    )\n",
    "+    #    add_executable(harness_rnnt\n",
    "+    #        harness_rnnt/main_rnnt.cc\n",
    "+    #        harness_rnnt/rnnt_kernels.cu\n",
    "+    #        common/logger.cpp\n",
    "+    #    )\n",
    "\n",
    "     # Add gencode compilation option for SOC (Xavier, Orin)\n",
    "-    if (${IS_SOC})\n",
    "-        message(STATUS \"Compiling RNNT harness for SM${SOC_SM}.\")\n",
    "-        target_compile_options(harness_rnnt PRIVATE $<$<COMPILE_LANGUAGE:CUDA>: -gencode arch=compute_${SOC_SM},code=sm_${SOC_SM}>)\n",
    "-    endif()\n",
    "-\n",
    "-    target_link_directories(harness_rnnt PRIVATE ${DALI_LIB_DIR})\n",
    "-\n",
    "-    target_link_libraries(harness_rnnt\n",
    "-        nvinfer\n",
    "-        nvinfer_plugin\n",
    "-        gflags\n",
    "-        glog\n",
    "-        ${CUDA_LIBRARIES}\n",
    "-        ${LOADGEN_LIB}\n",
    "-        ${DALI_LIBRARIES}\n",
    "-    )\n",
    "-\n",
    "-    target_include_directories(harness_rnnt\n",
    "-        PUBLIC\n",
    "-            ${CUDA_INCLUDE_DIRS}\n",
    "-            ${LOADGEN_INCLUDE_DIR}\n",
    "-            ${LWIS_INCLUDE_DIR}\n",
    "-            ${DALI_INCLUDE_DIR}\n",
    "-            common\n",
    "-            harness_rnnt\n",
    "-    )\n",
    "+    #    if (${IS_SOC})\n",
    "+    #        message(STATUS \"Compiling RNNT harness for SM${SOC_SM}.\")\n",
    "+    #        target_compile_options(harness_rnnt PRIVATE $<$<COMPILE_LANGUAGE:CUDA>: -gencode arch=compute_${SOC_SM},code=sm_${SOC_SM}>)\n",
    "+    #    endif()\n",
    "+\n",
    "+    #    target_link_directories(harness_rnnt PRIVATE ${DALI_LIB_DIR})\n",
    "+\n",
    "+    #    target_link_libraries(harness_rnnt\n",
    "+    #        nvinfer\n",
    "+    #        nvinfer_plugin\n",
    "+    #        gflags\n",
    "+    #        glog\n",
    "+    #        ${CUDA_LIBRARIES}\n",
    "+    #        ${LOADGEN_LIB}\n",
    "+    #        ${DALI_LIBRARIES}\n",
    "+    #    )\n",
    "+\n",
    "+    #    target_include_directories(harness_rnnt\n",
    "+    #        PUBLIC\n",
    "+    #            ${CUDA_INCLUDE_DIRS}\n",
    "+    #            ${LOADGEN_INCLUDE_DIR}\n",
    "+    #            ${LWIS_INCLUDE_DIR}\n",
    "+    #            ${DALI_INCLUDE_DIR}\n",
    "+    #            common\n",
    "+    #            harness_rnnt\n",
    "+    #    )\n",
    "\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make build\n",
    "...\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>$ ls -la build/\n",
    "total 28\n",
    "\n",
    "total 40\n",
    "drwxrwsr-x 10 katya krai 4096 May 19 16:36 .\n",
    "drwxrwsr-x 15 katya krai 4096 May 19 15:35 ..\n",
    "drwxr-sr-x  2 katya krai 4096 May 19 16:11 bin\n",
    "lrwxrwxrwx  1 katya krai   29 May 19 16:36 data -> /datasets/nvidia_scratch/data\n",
    "drwxr-sr-x  3 katya krai 4096 May 19 14:20 engines\n",
    "drwxrwsr-x  5 katya krai 4096 May 19 16:11 harness\n",
    "drwxrwsr-x 14 katya krai 4096 May 19 11:22 inference\n",
    "drwxrwsr-x  8 katya krai 4096 May 19 16:36 logs\n",
    "lrwxrwxrwx  1 katya krai   31 May 19 16:36 models -> /datasets/nvidia_scratch/models\n",
    "drwxrwsr-x  6 katya krai 4096 May 19 11:36 plugins\n",
    "drwxrwsr-x  9 katya krai 4096 May 19 11:22 power-dev\n",
    "lrwxrwxrwx  1 katya krai   42 May 19 16:36 preprocessed_data -> /datasets/nvidia_scratch/preprocessed_data\n",
    "drwxrwsr-x 10 katya krai 4096 May 19 11:23 triton-inference-server\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50\"></a>\n",
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline\"></a>\n",
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make generate_engines RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=offline&quot;\n",
    "...\n",
    "[2022-05-20 10:41:20,200 main.py:137 INFO] Finished building engines for resnet50 benchmark in Offline scenario.\n",
    "Time taken to generate engines: 265.04155135154724 seconds\n",
    "\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name resnet50-Offline*.plan -exec du -hs {} \\;\n",
    "27M     ./build/engines/Orin/resnet50/Offline/resnet50-Offline-gpu-b256-int8.lwis_k_99_MaxP.plan\n",
    "26M     ./build/engines/Orin/resnet50/Offline/resnet50-Offline-dla-b8-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/Offline/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per second: 6138.84\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment (after system reboot!)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=Offline --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-22 23:59:24,613 main.py:304 INFO] Result: result_samples_per_second: 5738.38, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: result_samples_per_second: 5738.38, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    11m7.798s\n",
    "user    11m1.016s\n",
    "sys     0m9.948s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/Offline/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "accuracy=76.038%, good=38019, total=50000\n",
    "hash=070aa1cee196b65944c4d0f7778135ab66c849bf1374eb4ccbc0aa43cddbc9ff\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=Offline --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "accuracy=76.038%, good=38019, total=50000 TO UPDATE\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: Accuracy = 76.038, Threshold = 75.695. Accuracy test PASSED.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream\"></a>\n",
    "## SingleStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=singlestream&quot;\n",
    "...\n",
    "[2022-05-24 13:06:32,113 main.py:137 INFO] Finished building engines for resnet50 benchmark in SingleStream scenario.\n",
    "Time taken to generate engines: 40.654820680618286 seconds\n",
    "\n",
    "real    0m44.579s\n",
    "user    0m21.267s\n",
    "sys     0m7.008s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name resnet50-SingleStream*.plan -exec du -hs {} \\;\n",
    "27M     ./build/engines/Orin/resnet50/SingleStream/resnet50-SingleStream-gpu-b1-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/SingleStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "90th percentile latency (ns) : 694827\n",
    "Result is : VALID\n",
    "  Min duration satisfied : Yes\n",
    "  Min queries satisfied : Yes\n",
    "  Early stopping satisfied: Yes\n",
    "Early Stopping Result:\n",
    " * Processed at least 64 queries (861139).\n",
    " * Would discard 85465 highest latency queries.\n",
    " * Early stopping 90th percentile estimate: 694858\n",
    " * Early stopping 99th percentile estimate: 698315\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=SingleStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    resnet50: result_90.00_percentile_latency_ns: 724114, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    resnet50: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    10m19.950s\n",
    "user    1m41.248s\n",
    "sys     0m40.173s\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/SingleStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "accuracy=76.030%, good=38015, total=50000\n",
    "hash=f7aabe1e91e185d900dc060ca6e7f0fc2f57b1b5cbd447c31411cf06a93150b4\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=SingleStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "accuracy=76.040%, good=38020, total=50000\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    resnet50: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    resnet50: Accuracy = 76.040, Threshold = 75.695. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    3m49.734s\n",
    "user    0m31.405s\n",
    "sys     0m16.638s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream\"></a>\n",
    "## MultiStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=multistream&quot;\n",
    "...\n",
    "[2022-05-24 13:08:06,236 main.py:137 INFO] Finished building engines for resnet50 benchmark in MultiStream scenario.\n",
    "Time taken to generate engines: 34.90856742858887 seconds\n",
    "\n",
    "real    0m38.929s\n",
    "user    0m19.816s\n",
    "sys     0m8.275s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name resnet50-MultiStream*.plan -exec du -hs {} \\;\n",
    "27M     ./build/engines/Orin/resnet50/MultiStream/resnet50-MultiStream-gpu-b8-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/MultiStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "99th percentile latency (ns) : 3956535\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Our experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=MultiStream --test_mode=PerformanceOnly&quot;\n",
    "\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    resnet50: result_99.00_percentile_per_query_latency_ns: 2352684, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    resnet50: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    10m17.854s\n",
    "user    1m23.250s\n",
    "sys     0m17.760s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/MultiStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "accuracy=76.030%, good=38015, total=50000\n",
    "hash=acf6aabdb21f556665ebb5dcbf04a11228fea64368c4485ce325f2362e00d909\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=MultiStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "accuracy=76.040%, good=38020, total=50000\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    resnet50: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    resnet50: Accuracy = 76.040, Threshold = 75.695. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    2m19.813s\n",
    "user    0m25.461s\n",
    "sys     0m11.814s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert\"></a>\n",
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline\"></a>\n",
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=bert --scenarios=offline&quot;\n",
    "...\n",
    "Time taken to generate engines: 4379.266929149628 seconds\n",
    "\n",
    "real    73m3.881s\n",
    "user    0m32.668s\n",
    "sys     16m22.002s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name bert-Offline*.plan -exec du -hs {} \\;\n",
    "355M    ./build/engines/Orin/bert/Offline/bert-Offline-gpu-int8_S_384_B_256_P_1_vs_il.custom_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/bert-99/Offline/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per second: 476.344\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=bert --scenarios=Offline --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-23 02:00:20,632 main.py:304 INFO] Result: result_samples_per_second: 482.61, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-Offline:\n",
    "    bert: result_samples_per_second: 482.61, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-Offline:\n",
    "    bert: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    11m18.494s\n",
    "user    0m9.500s\n",
    "sys     0m2.521s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/bert-99/Offline/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "{\"exact_match\": 82.687, \"f1\": 90.104}\n",
    "hash=f56718adf61873042f22ce72c152f015b8ac1057a658676ba39c505c2b6f22cf\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=bert --scenarios=Offline --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-Offline:\n",
    "    bert: Accuracy = 90.104, Threshold = 89.965. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    1m54.490s\n",
    "user    1m17.205s\n",
    "sys     0m1.996s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_singlestream\"></a>\n",
    "## SingleStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_singlestream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=bert --scenarios=singlestream&quot;\n",
    "...\n",
    "[2022-05-24 14:43:33,052 main.py:137 INFO] Finished building engines for bert benchmark in SingleStream scenario.\n",
    "Time taken to generate engines: 67.85338068008423 seconds\n",
    "\n",
    "real    1m12.345s\n",
    "user    0m33.929s\n",
    "sys     0m12.486s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name bert-SingleStream*.plan -exec du -hs {} \\;\n",
    "354M    ./build/engines/Orin/bert/SingleStream/bert-SingleStream-gpu-int8_S_384_B_1_P_1_vs.custom_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_singlestream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/bert-99/SingleStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "90th percentile latency (ns) : 7634138\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=bert --scenarios=SingleStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-24 14:58:48,681 main.py:304 INFO] Result: result_90.00_percentile_latency_ns: 8173938, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-SingleStream:\n",
    "    bert: result_90.00_percentile_latency_ns: 8173938, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-SingleStream:\n",
    "    bert: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    10m6.405s\n",
    "user    4m2.775s\n",
    "sys     0m6.617s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_singlestream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/bert-99/SingleStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "{\"exact_match\": 83.245, \"f1\": 90.445}\n",
    "hash=76ded78de16cdd33c6a8f95ec5a92907234ae8bf850057bc36dc90d0f22fbbd6\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=bert --scenarios=SingleStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-SingleStream:\n",
    "    bert: Accuracy = 90.440, Threshold = 89.965. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    2m29.181s\n",
    "user    1m46.591s\n",
    "sys     0m2.966s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet\"></a>\n",
    "# SSD-MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_offline\"></a>\n",
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_offline_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=offline&quot;\n",
    "...\n",
    "[2022-05-24 16:16:00,182 main.py:137 INFO] Finished building engines for ssd-mobilenet benchmark in Offline scenario.\n",
    "Time taken to generate engines: 352.52208948135376 seconds\n",
    "\n",
    "real    5m57.185s\n",
    "user    3m14.667s\n",
    "sys     1m15.765s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-mobilenet-Offline*.plan -exec du -hs {} \\;\n",
    "23M     ./build/engines/Orin/ssd-mobilenet/Offline/ssd-mobilenet-Offline-dla-b64-int8.lwis_k_99_MaxP.plan\n",
    "8.3M    ./build/engines/Orin/ssd-mobilenet/Offline/ssd-mobilenet-Offline-gpu-b128-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_offline_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-mobilenet/Offline/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per second: 6883.49\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=Offline --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-24 16:31:29,790 main.py:304 INFO] Result: result_samples_per_second: 6744.67, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    ssd-mobilenet: result_samples_per_second: 6744.67, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    ssd-mobilenet: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    11m53.101s\n",
    "user    11m40.497s\n",
    "sys     0m4.586s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_offline_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-mobilenet/Offline/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n",
    "mAP=22.861%\n",
    "hash=1b8328272ef4ff9d38b6640151584af6d9e7db27cc7ca74830fd8e95ad4835e5\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=Offline --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    ssd-mobilenet: Accuracy = 22.876, Threshold = 21.780. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    1m3.479s\n",
    "user    0m27.640s\n",
    "sys     0m3.919s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_singlestream\"></a>\n",
    "## SingleStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_singlestream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=singlestream&quot;\n",
    "...\n",
    "[2022-05-24 16:56:19,282 main.py:137 INFO] Finished building engines for ssd-mobilenet benchmark in SingleStream scenario.\n",
    "Time taken to generate engines: 75.95014977455139 seconds\n",
    "\n",
    "real    1m20.457s\n",
    "user    1m1.072s\n",
    "sys     0m12.098s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-mobilenet-SingleStream*.plan -exec du -hs {} \\;\n",
    "8.4M    ./build/engines/Orin/ssd-mobilenet/SingleStream/ssd-mobilenet-SingleStream-gpu-b1-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_singlestream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-mobilenet/SingleStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "90th percentile latency (ns) : 473641\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=SingleStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-24 17:13:37,435 main.py:304 INFO] Result: result_90.00_percentile_latency_ns: 531497, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    ssd-mobilenet: result_90.00_percentile_latency_ns: 531497, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    ssd-mobilenet: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    10m13.537s\n",
    "user    2m58.244s\n",
    "sys     0m52.462s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_singlestream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-mobilenet/SingleStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.261\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
    "mAP=22.914%\n",
    "hash=52c4ac8a051c244379e3f497330550e84b976557577827f5e290c4873b56594a\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=SingleStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    ssd-mobilenet: Accuracy = 22.914, Threshold = 21.780. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    0m37.466s\n",
    "user    0m27.414s\n",
    "sys     0m6.092s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_multistream\"></a>\n",
    "## MultiStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_multistream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=multistream&quot;\n",
    "...\n",
    "[2022-05-24 17:01:32,444 main.py:137 INFO] Finished building engines for ssd-mobilenet benchmark in MultiStream scenario.\n",
    "Time taken to generate engines: 81.45282483100891 seconds\n",
    "\n",
    "real    1m25.974s\n",
    "user    0m59.426s\n",
    "sys     0m14.775s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-mobilenet-MultiStream*.plan -exec du -hs {} \\;\n",
    "8.1M    ./build/engines/Orin/ssd-mobilenet/MultiStream/ssd-mobilenet-MultiStream-gpu-b8-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_multistream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-mobilenet/MultiStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "99th percentile latency (ns) : 4266439\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Our experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=MultiStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-24 17:45:44,125 main.py:304 INFO] Result: result_99.00_percentile_per_query_latency_ns: 2041312, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    ssd-mobilenet: result_99.00_percentile_per_query_latency_ns: 2041312, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    ssd-mobilenet: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    10m11.801s\n",
    "user    2m42.124s\n",
    "sys     0m15.989s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-mobilenet_multistream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-mobilenet/MultiStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.261\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
    "mAP=22.914%\n",
    "hash=53cc6074ee0c9a5510f9d190cc9b73e6b52e3ffc2d3aba6db4e93d4a6c7934e1\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-mobilenet --scenarios=MultiStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    ssd-mobilenet: Accuracy = 22.914, Threshold = 21.780. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    0m36.379s\n",
    "user    0m27.289s\n",
    "sys     0m5.944s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34\"></a>\n",
    "# SSD-ResNet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline\"></a>\n",
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=offline&quot;\n",
    "...\n",
    "[2022-05-24 09:37:25,912 main.py:137 INFO] Finished building engines for ssd-resnet34 benchmark in Offline scenario.\n",
    "Time taken to generate engines: 577.0244572162628 seconds\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-resnet34-Offline*.plan -exec du -hs {} \\;\n",
    "30M     ./build/engines/Orin/ssd-resnet34/Offline/ssd-resnet34-Offline-dla-b8-int8.lwis_k_99_MaxP.plan\n",
    "23M     ./build/engines/Orin/ssd-resnet34/Offline/ssd-resnet34-Offline-gpu-b8-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-resnet34/Offline/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per second: 207.657\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Our experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=Offline --test_mode=PerformanceOnly&quot;\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    ssd-resnet34: result_samples_per_second: 177.848, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    ssd-resnet34: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    11m40.392s\n",
    "user    11m31.448s\n",
    "sys     0m3.255s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-resnet34/Offline/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.428\n",
    "mAP=19.909%\n",
    "hash=615698dac9c5f0889acd9c626a5241781466b9699c8e57ff1773ce2739f310bf\n",
    "</pre>\n",
    "\n",
    "#### Our experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=Offline --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.374\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.329\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
    "mAP=19.746%\n",
    "Traceback (most recent call last):\n",
    "  File \"code/main.py\", line 772, in <module>\n",
    "    main(main_args, DETECTED_SYSTEM)\n",
    "  File \"code/main.py\", line 744, in main\n",
    "    dispatch_action(main_args, config_dict, workload_id, equiv_engine_setting=equiv_engine_setting)\n",
    "  File \"code/main.py\", line 574, in dispatch_action\n",
    "    handle_run_harness(benchmark_conf, need_gpu, need_dla, profile, power)\n",
    "  File \"code/main.py\", line 339, in handle_run_harness\n",
    "    accuracy = check_accuracy(os.path.join(harness.get_full_log_dir(), \"mlperf_log_accuracy.json\"), config)\n",
    "  File \"code/main.py\", line 497, in check_accuracy\n",
    "    raise RuntimeError(\n",
    "RuntimeError: Accuracy = 19.746, Threshold = 19.800. Accuracy test FAILED!\n",
    "make: *** [Makefile:699: run_harness] Error 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream\"></a>\n",
    "## SingleStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=singlestream&quot;\n",
    "...\n",
    "[2022-05-24 10:28:50,980 main.py:137 INFO] Finished building engines for ssd-resnet34 benchmark in SingleStream scenario.\n",
    "Time taken to generate engines: 164.7405767440796 seconds\n",
    "\n",
    "real    2m48.949s\n",
    "user    2m29.160s\n",
    "sys     1m30.652s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-resnet34-SingleStream*.plan -exec du -hs {} \\;\n",
    "26M     ./build/engines/Orin/ssd-resnet34/SingleStream/ssd-resnet34-SingleStream-gpu-b1-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-resnet34/SingleStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "90th percentile latency (ns) : 8028243\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=SingleStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    ssd-resnet34: result_90.00_percentile_latency_ns: 8130504, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    ssd-resnet34: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    10m10.330s\n",
    "user    0m43.939s\n",
    "sys     0m8.899s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-resnet34/SingleStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
    "mAP=20.113%\n",
    "hash=267e70f78d746992c5142008643dd2f2d9d95424715491aabfe63b3e68e4893c\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=SingleStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.428\n",
    "mAP=19.913%\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    ssd-resnet34: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-SingleStream:\n",
    "    ssd-resnet34: Accuracy = 19.913, Threshold = 19.800. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    7m11.931s\n",
    "user    2m28.669s\n",
    "sys     0m24.538s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream\"></a>\n",
    "## MultiStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=multistream&quot;\n",
    "...\n",
    "[2022-05-24 10:47:04,101 main.py:137 INFO] Finished building engines for ssd-resnet34 benchmark in MultiStream scenario.\n",
    "Time taken to generate engines: 185.63524317741394 seconds\n",
    "\n",
    "real    3m9.988s\n",
    "user    2m29.871s\n",
    "sys     1m40.165s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-resnet34-MultiStream*.plan -exec du -hs {} \\;\n",
    "25M     ./build/engines/Orin/ssd-resnet34/MultiStream/ssd-resnet34-MultiStream-gpu-b2-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-resnet34/MultiStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "99th percentile latency (ns) : 60667403\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin/b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=MultiStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    ssd-resnet34: result_99.00_percentile_per_query_latency_ns: 61004829, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    ssd-resnet34: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    60m10.226s\n",
    "user    45m14.797s\n",
    "sys     0m9.696s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/ssd-resnet34/MultiStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
    "mAP=20.113%\n",
    "hash=419a56265f86193ebaf1e53c39c8b5bf308f9f99651f4d1b615b0468179bd44c\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=MultiStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
    "mAP=19.891%\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    ssd-resnet34: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-MultiStream:\n",
    "    ssd-resnet34: Accuracy = 19.891, Threshold = 19.800. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    4m30.403s\n",
    "user    2m51.865s\n",
    "sys     0m17.264s\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
