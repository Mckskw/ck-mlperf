{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPerf Inference v2.0 - Reproducing Orin results with JetPack 4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [System](#system)\n",
    "1. [Installation](#installation)\n",
    "    1. [Clone the repo](#installation_repo)\n",
    "    1. [Install the dependencies](#installation_deps)\n",
    "    1. [Link the datasets](#installation_datasets)\n",
    "    1. [Download the models](#installation_models)\n",
    "    1. [Build the harness](#installation_harness)\n",
    "1. [ResNet50](#resnet50)\n",
    "    1. [Offline](#resnet50_offline)\n",
    "        1. [Build](#resnet50_offline_build)\n",
    "        1. [Performance](#resnet50_offline_performance)\n",
    "        1. [Accuracy](#resnet50_offline_accuracy)\n",
    "    1. [SingleStream](#resnet50_singlestream)\n",
    "        1. [Build](#resnet50_singlestream_build)\n",
    "        1. [Performance](#resnet50_singlestream_performance)\n",
    "        1. [Accuracy](#resnet50_singlestream_accuracy)\n",
    "    1. [MultiStream](#resnet50_multistream)\n",
    "        1. [Build](#resnet50_multistream_build)\n",
    "        1. [Performance](#resnet50_multistream_performance)\n",
    "        1. [Accuracy](#resnet50_multistream_accuracy)\n",
    "1. [SSD-ResNet34](#ssd-resnet34)\n",
    "    1. [Offline](#ssd-resnet34_offline)\n",
    "        1. [Build](#ssd-resnet34_offline_build)\n",
    "        1. [Performance](#ssd-resnet34_offline_performance)\n",
    "        1. [Accuracy](#ssd-resnet34_offline_accuracy)\n",
    "    1. [SingleStream](#ssd-resnet34_singlestream)\n",
    "        1. [Build](#ssd-resnet34_singlestream_build)\n",
    "        1. [Performance](#ssd-resnet34_singlestream_performance)\n",
    "        1. [Accuracy](#ssd-resnet34_singlestream_accuracy)\n",
    "    1. [MultiStream](#ssd-resnet34_multistream)\n",
    "        1. [Build](#ssd-resnet34_multistream_build)\n",
    "        1. [Performance](#ssd-resnet34_multistream_performance)\n",
    "        1. [Accuracy](#ssd-resnet34_multistream_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"system\"></a>\n",
    "# System: [NVIDIA Orin](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/systems/Orin_TRT.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats: JetPack\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; sudo -H python3 -m pip install jetson-stats -U\n",
    "...\n",
    "Successfully installed jetson-stats-3.1.0\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; jetson_release\n",
    "\n",
    " - NVIDIA Jetson UNKNOWN\n",
    "   * Jetpack UNKNOWN [L4T 34.1.0]\n",
    "   * NV Power Mode: MAXN - Type: 0\n",
    "   * jetson_stats.service: active\n",
    " - Libraries:\n",
    "   * CUDA: NOT_INSTALLED\n",
    "   * cuDNN: 8.3.2.49\n",
    "   * TensorRT: 8.4.0.9\n",
    "   * Visionworks: NOT_INSTALLED\n",
    "   * OpenCV: 4.5.4 compiled CUDA: NO\n",
    "   * VPI: ii libnvvpi2 2.0.9 arm64 NVIDIA Vision Programming Interface library\n",
    "   * Vulkan: 1.3.203\n",
    "</pre>\n",
    "\n",
    "## OS: Ubuntu 18.04.5 LTS\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; cat /etc/lsb-release\n",
    "DISTRIB_ID=Ubuntu\n",
    "DISTRIB_RELEASE=20.04\n",
    "DISTRIB_CODENAME=focal\n",
    "DISTRIB_DESCRIPTION=&quot;Ubuntu 20.04.4 LTS&quot;\n",
    "</pre>\n",
    "\n",
    "## CPU: 12-core ARMv81 @ 2200 MHz\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; lscpu\n",
    "Architecture:                    aarch64\n",
    "CPU op-mode(s):                  32-bit, 64-bit\n",
    "Byte Order:                      Little Endian\n",
    "CPU(s):                          12\n",
    "On-line CPU(s) list:             0-11\n",
    "Thread(s) per core:              1\n",
    "Core(s) per socket:              4\n",
    "Socket(s):                       3\n",
    "Vendor ID:                       ARM\n",
    "Model:                           1\n",
    "Model name:                      ARMv8 Processor rev 1 (v8l)\n",
    "Stepping:                        r0p1\n",
    "CPU max MHz:                     2201.6001\n",
    "CPU min MHz:                     115.2000\n",
    "BogoMIPS:                        62.50\n",
    "L1d cache:                       768 KiB\n",
    "L1i cache:                       768 KiB\n",
    "L2 cache:                        3 MiB\n",
    "L3 cache:                        6 MiB\n",
    "Vulnerability Itlb multihit:     Not affected\n",
    "Vulnerability L1tf:              Not affected\n",
    "Vulnerability Mds:               Not affected\n",
    "Vulnerability Meltdown:          Not affected\n",
    "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
    "Vulnerability Spectre v1:        Mitigation; __user pointer sanitization\n",
    "Vulnerability Spectre v2:        Not affected\n",
    "Vulnerability Srbds:             Not affected\n",
    "Vulnerability Tsx async abort:   Not affected\n",
    "Flags:                           fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm lrcpc dcpop asimddp uscat ilrcpc flagm\n",
    "</pre>\n",
    "\n",
    "## GPU\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; sudo jetson_clocks\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; sudo jetson_clocks --show\n",
    "SOC family:tegra234  Machine:NVIDIA Orin Jetson-Small Developer Kit\n",
    "Online CPUs: 0-11\n",
    "cpu0: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu1: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu10: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu11: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu2: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu3: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu4: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu5: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu6: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu7: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu8: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "cpu9: Online=1 Governor=schedutil MinFreq=2201600 MaxFreq=2201600 CurrentFreq=2201600 IdleStates: WFI=0 c7=0\n",
    "GPU MinFreq=1300500000 MaxFreq=1300500000 CurrentFreq=1300500000\n",
    "EMC MinFreq=204000000 MaxFreq=3199000000 CurrentFreq=3199000000 FreqOverride=1\n",
    "DLA0_CORE MinFreq=0 MaxFreq=1536000000 CurrentFreq=1536000000\n",
    "DLA0_FALCON MinFreq=0 MaxFreq=832000000 CurrentFreq=832000000\n",
    "DLA1_CORE MinFreq=0 MaxFreq=1536000000 CurrentFreq=1536000000\n",
    "DLA1_FALCON MinFreq=0 MaxFreq=832000000 CurrentFreq=832000000\n",
    "PVA0_VPS0 MinFreq=0 MaxFreq=1152000000 CurrentFreq=1152000000\n",
    "PVA0_AXI MinFreq=0 MaxFreq=832000000 CurrentFreq=832000000\n",
    "FAN Dynamic Speed control=active hwmon3_pwm=88\n",
    "NV Power Mode: MAXN\n",
    "</pre>\n",
    "\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; ck compile program:tool-print-cuda-devices\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; ck run program:tool-print-cuda-devices\n",
    "...\n",
    "GPU Device ID: 0\n",
    "GPU Name: Orin\n",
    "GPU compute capability: 8.7\n",
    "CUDA driver version: 11.4\n",
    "CUDA runtime version: 11.4\n",
    "Global memory: 32110174208\n",
    "Max clock rate: 1300.000000 MHz\n",
    "Total amount of shared memory per block: 49152\n",
    "Total number of registers available per block: 65536\n",
    "Warp size: 32\n",
    "Maximum number of threads per multiprocessor:  1536\n",
    "Maximum number of threads per block: 1024\n",
    "Max dimension size of a thread block X: 1024\n",
    "Max dimension size of a thread block Y: 1024\n",
    "Max dimension size of a thread block Z: 64\n",
    "Max dimension size of a grid size X: 2147483647\n",
    "Max dimension size of a grid size Y: 65535\n",
    "Max dimension size of a grid size Z: 65535\n",
    "</pre>\n",
    "\n",
    "\n",
    "## Disks\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; df -h\n",
    "Filesystem      Size  Used Avail Use% Mounted on\n",
    "/dev/mmcblk0p1   57G   18G   37G  33% /\n",
    "none             15G     0   15G   0% /dev\n",
    "tmpfs            15G   52K   15G   1% /dev/shm\n",
    "tmpfs           3.0G   11M  3.0G   1% /run\n",
    "tmpfs           5.0M  4.0K  5.0M   1% /run/lock\n",
    "tmpfs            15G     0   15G   0% /sys/fs/cgroup\n",
    "/dev/mmcblk1p1  469G   36G  409G   9% /sd\n",
    "tmpfs           3.0G   16K  3.0G   1% /run/user/124\n",
    "tmpfs           3.0G  4.0K  3.0G   1% /run/user/1000\n",
    "tmpfs           3.0G  8.0K  3.0G   1% /run/user/1001\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation\"></a>\n",
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation_repo\"></a>\n",
    "## Clone the v2.0 results repo\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; git clone https://github.com/mlcommons/inference_results_v2.0.git</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation_deps\"></a>\n",
    "## Install the dependencies\n",
    "\n",
    "To [quote](https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure) Azure:\n",
    "> Note that this might take a while, on the order of several hours.\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; chmod +x inference_results_v2.0/closed/Azure/scripts/install_orin_jetson_dependencies.sh\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; time sudo inference_results_v2.0/closed/Azure/scripts/install_orin_jetson_dependencies.sh\n",
    "<font color=\"#859900\"><b>anton@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; python3 -m pip install onnx\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"installation_datasets\"></a>\n",
    "\n",
    "<pre>\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; echo 'export MLPERF_SCRATCH_PATH=/datasets/nvidia_scratch' >> $HOME/.bashrc\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; source $HOME/.bashrc\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; mkdir &dollar;MLPERF_SCRATCH_PATH\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>~</b></font>&dollar; cd &dollar;MLPERF_SCRATCH_PATH\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/nvidia_scratch</b></font>&dollar; mkdir data models preprocessed_data\n",
    "<font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/mlperf_scratch_path</b></font>&dollar; ls -la /datasets/nvidia_scratch/\n",
    "total 20\n",
    "drwxrwsr-x  3 anton dvdt 4096 Jan 28 11:10 <font color=\"#268BD2\"><b>.</b></font>\n",
    "drwxrwsr-x 17 root  dvdt 4096 Jan 28 09:53 <font color=\"#268BD2\"><b>..</b></font>\n",
    "lrwxrwxrwx  1 anton dvdt   64 Jan 28 11:10 <font color=\"#2AA198\"><b>data</b></font> \n",
    "drwxrwsr-x  5 anton dvdt 4096 Jan 28 09:54 <font color=\"#268BD2\"><b>models</b></font>\n",
    "lrwxrwxrwx  1 anton dvdt   77 Jan 28 11:10 <font color=\"#2AA198\"><b>preprocessed_data</b></font> \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"download_datasets\"></a>\n",
    "## Download the datasets\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>:/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; bash code/bert/tensorrt/download_data.sh\n",
    "\n",
    "<a name=\"installation_models\"></a>\n",
    "## Download the models\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>:/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make download_model BENCHMARKS=\"resnet50,bert\"\n",
    "...\n",
    "Finished downloading all the models!\n",
    "</pre>\n",
    "\n",
    "## Preprocess the dataset\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>:/datasets/inference_results_v2.0/closed/Azure</b></font>&dollar; make preprocess_data BENCHMARKS=\"resnet50,bert\"\n",
    "</pre>\n",
    "\n",
    "## Build the binaries\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; git diff code/harness/CMakeLists.txt\n",
    "\n",
    "diff --git a/closed/NVIDIA/code/harness/CMakeLists.txt b/closed/NVIDIA/code/harness/CMakeLists.txt\n",
    "index 074c0bc25..b205e7691 100644\n",
    "--- a/closed/NVIDIA/code/harness/CMakeLists.txt\n",
    "+++ b/closed/NVIDIA/code/harness/CMakeLists.txt\n",
    "@@ -503,48 +503,48 @@ else()\n",
    "     )\n",
    "\n",
    "     ######### RNN-T HARNESS ########\n",
    "-    execute_process(COMMAND echo \"Building RNN-T harness...\")\n",
    "+    #    execute_process(COMMAND echo \"Building RNN-T harness...\")\n",
    "\n",
    "-    get_dali_paths(DALI_INCLUDE_DIR DALI_LIB_DIR DALI_LIBRARIES)\n",
    "+    #    get_dali_paths(DALI_INCLUDE_DIR DALI_LIB_DIR DALI_LIBRARIES)\n",
    "\n",
    "-    message(STATUS \"DALI libraries DIR: \" ${DALI_LIB_DIR})\n",
    "-    message(STATUS \"DALI include DIR: \" ${DALI_INCLUDE_DIR})\n",
    "+    #    message(STATUS \"DALI libraries DIR: \" ${DALI_LIB_DIR})\n",
    "+    #    message(STATUS \"DALI include DIR: \" ${DALI_INCLUDE_DIR})\n",
    "\n",
    "-    message(STATUS \"DALI linked libraries: \" ${DALI_LIBRARIES})\n",
    "+    #    message(STATUS \"DALI linked libraries: \" ${DALI_LIBRARIES})\n",
    "\n",
    "-    add_executable(harness_rnnt\n",
    "-        harness_rnnt/main_rnnt.cc\n",
    "-        harness_rnnt/rnnt_kernels.cu\n",
    "-        common/logger.cpp\n",
    "-    )\n",
    "+    #    add_executable(harness_rnnt\n",
    "+    #        harness_rnnt/main_rnnt.cc\n",
    "+    #        harness_rnnt/rnnt_kernels.cu\n",
    "+    #        common/logger.cpp\n",
    "+    #    )\n",
    "\n",
    "     # Add gencode compilation option for SOC (Xavier, Orin)\n",
    "-    if (${IS_SOC})\n",
    "-        message(STATUS \"Compiling RNNT harness for SM${SOC_SM}.\")\n",
    "-        target_compile_options(harness_rnnt PRIVATE $<$<COMPILE_LANGUAGE:CUDA>: -gencode arch=compute_${SOC_SM},code=sm_${SOC_SM}>)\n",
    "-    endif()\n",
    "-\n",
    "-    target_link_directories(harness_rnnt PRIVATE ${DALI_LIB_DIR})\n",
    "-\n",
    "-    target_link_libraries(harness_rnnt\n",
    "-        nvinfer\n",
    "-        nvinfer_plugin\n",
    "-        gflags\n",
    "-        glog\n",
    "-        ${CUDA_LIBRARIES}\n",
    "-        ${LOADGEN_LIB}\n",
    "-        ${DALI_LIBRARIES}\n",
    "-    )\n",
    "-\n",
    "-    target_include_directories(harness_rnnt\n",
    "-        PUBLIC\n",
    "-            ${CUDA_INCLUDE_DIRS}\n",
    "-            ${LOADGEN_INCLUDE_DIR}\n",
    "-            ${LWIS_INCLUDE_DIR}\n",
    "-            ${DALI_INCLUDE_DIR}\n",
    "-            common\n",
    "-            harness_rnnt\n",
    "-    )\n",
    "+    #    if (${IS_SOC})\n",
    "+    #        message(STATUS \"Compiling RNNT harness for SM${SOC_SM}.\")\n",
    "+    #        target_compile_options(harness_rnnt PRIVATE $<$<COMPILE_LANGUAGE:CUDA>: -gencode arch=compute_${SOC_SM},code=sm_${SOC_SM}>)\n",
    "+    #    endif()\n",
    "+\n",
    "+    #    target_link_directories(harness_rnnt PRIVATE ${DALI_LIB_DIR})\n",
    "+\n",
    "+    #    target_link_libraries(harness_rnnt\n",
    "+    #        nvinfer\n",
    "+    #        nvinfer_plugin\n",
    "+    #        gflags\n",
    "+    #        glog\n",
    "+    #        ${CUDA_LIBRARIES}\n",
    "+    #        ${LOADGEN_LIB}\n",
    "+    #        ${DALI_LIBRARIES}\n",
    "+    #    )\n",
    "+\n",
    "+    #    target_include_directories(harness_rnnt\n",
    "+    #        PUBLIC\n",
    "+    #            ${CUDA_INCLUDE_DIRS}\n",
    "+    #            ${LOADGEN_INCLUDE_DIR}\n",
    "+    #            ${LWIS_INCLUDE_DIR}\n",
    "+    #            ${DALI_INCLUDE_DIR}\n",
    "+    #            common\n",
    "+    #            harness_rnnt\n",
    "+    #    )\n",
    "\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make build\n",
    "...\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>$ ls -la build/\n",
    "total 28\n",
    "\n",
    "total 40\n",
    "drwxrwsr-x 10 katya krai 4096 May 19 16:36 .\n",
    "drwxrwsr-x 15 katya krai 4096 May 19 15:35 ..\n",
    "drwxr-sr-x  2 katya krai 4096 May 19 16:11 bin\n",
    "lrwxrwxrwx  1 katya krai   29 May 19 16:36 data -> /datasets/nvidia_scratch/data\n",
    "drwxr-sr-x  3 katya krai 4096 May 19 14:20 engines\n",
    "drwxrwsr-x  5 katya krai 4096 May 19 16:11 harness\n",
    "drwxrwsr-x 14 katya krai 4096 May 19 11:22 inference\n",
    "drwxrwsr-x  8 katya krai 4096 May 19 16:36 logs\n",
    "lrwxrwxrwx  1 katya krai   31 May 19 16:36 models -> /datasets/nvidia_scratch/models\n",
    "drwxrwsr-x  6 katya krai 4096 May 19 11:36 plugins\n",
    "drwxrwsr-x  9 katya krai 4096 May 19 11:22 power-dev\n",
    "lrwxrwxrwx  1 katya krai   42 May 19 16:36 preprocessed_data -> /datasets/nvidia_scratch/preprocessed_data\n",
    "drwxrwsr-x 10 katya krai 4096 May 19 11:23 triton-inference-server\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50\"></a>\n",
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline\"></a>\n",
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make generate_engines RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=offline&quot;\n",
    "...\n",
    "[2022-05-20 10:41:20,200 main.py:137 INFO] Finished building engines for resnet50 benchmark in Offline scenario.\n",
    "Time taken to generate engines: 265.04155135154724 seconds\n",
    "\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name resnet50-Offline*.plan -exec du -hs {} \\;\n",
    "27M     ./build/engines/Orin/resnet50/Offline/resnet50-Offline-gpu-b256-int8.lwis_k_99_MaxP.plan\n",
    "26M     ./build/engines/Orin/resnet50/Offline/resnet50-Offline-dla-b8-int8.lwis_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/Offline/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per second: 6138.84\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment (after system reboot!)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; \n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=offline --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-22 23:59:24,613 main.py:304 INFO] Result: result_samples_per_second: 5738.38, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: result_samples_per_second: 5738.38, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    11m7.798s\n",
    "user    11m1.016s\n",
    "sys     0m9.948s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_offline_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/resnet50/Offline/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "accuracy=76.038%, good=38019, total=50000\n",
    "hash=070aa1cee196b65944c4d0f7778135ab66c849bf1374eb4ccbc0aa43cddbc9ff\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; \n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=offline --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "accuracy=76.038%, good=38019, total=50000 TO UPDATE\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-lwis_k_99_MaxP-Offline:\n",
    "    resnet50: Accuracy = 76.038, Threshold = 75.695. Accuracy test PASSED.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream\"></a>\n",
    "## SingleStream - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Config](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/configs/resnet50/SingleStream/config.json)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; grep AGX_Xavier /datasets/inference_results_v1.0/closed/NVIDIA/configs/resnet50/SingleStream/config.json -A 6\n",
    "    &quot;<font color=\"#DC322F\"><b>AGX_Xavier</b></font>&quot;: {\n",
    "        &quot;config_ver&quot;: {\n",
    "            &quot;maxq&quot;: {}\n",
    "        },\n",
    "        &quot;gpu_single_stream_expected_latency_ns&quot;: 2273000,\n",
    "        &quot;use_graphs&quot;: false\n",
    "    },\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=singlestream&quot;\n",
    "...\n",
    "[2021-04-27 17:35:34,949 main.py:112 INFO] Finished building engines for resnet50 benchmark in SingleStream scenario.\n",
    "Time taken to generate engines: 42.95994567871094 seconds\n",
    "\n",
    "real    0m44.209s\n",
    "user    0m23.192s\n",
    "sys     0m4.620s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name resnet50-SingleStream*.plan -exec du -hs {} \\;\n",
    "44M     ./build/engines/AGX_Xavier/resnet50/SingleStream/resnet50-SingleStream-gpu-b1-int8.default.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/resnet50/SingleStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "90th percentile latency (ns) : 1980582\n",
    "Result is : VALID\n",
    "  Min duration satisfied : Yes\n",
    "  Min queries satisfied : Yes\n",
    "...\n",
    "QPS w/ loadgen overhead         : 509.00\n",
    "QPS w/o loadgen overhead        : 512.43\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=SingleStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "================================================\n",
    "MLPerf Results Summary\n",
    "================================================\n",
    "SUT name : LWIS_Server\n",
    "Scenario : Single Stream\n",
    "Mode     : Performance\n",
    "90th percentile latency (ns) : 2078719\n",
    "Result is : VALID\n",
    "  Min duration satisfied : Yes\n",
    "  Min queries satisfied : Yes\n",
    "\n",
    "================================================\n",
    "Additional Stats\n",
    "================================================\n",
    "QPS w/ loadgen overhead         : 485.07\n",
    "QPS w/o loadgen overhead        : 488.48\n",
    "\n",
    "Min latency (ns)                : 1980890\n",
    "Max latency (ns)                : 15165301\n",
    "Mean latency (ns)               : 2047146\n",
    "50.00 percentile latency (ns)   : 2038621\n",
    "90.00 percentile latency (ns)   : 2078719\n",
    "95.00 percentile latency (ns)   : 2098912\n",
    "97.00 percentile latency (ns)   : 2118465\n",
    "99.00 percentile latency (ns)   : 2187844\n",
    "99.90 percentile latency (ns)   : 2564821\n",
    "\n",
    "================================================\n",
    "Test Parameters Used\n",
    "================================================\n",
    "samples_per_query : 1\n",
    "target_qps : 439.947\n",
    "target_latency (ns): 0\n",
    "max_async_queries : 1\n",
    "min_duration (ms): 60000\n",
    "max_duration (ms): 0\n",
    "min_query_count : 1024\n",
    "max_query_count : 0\n",
    "qsl_rng_seed : 12786827339337101903\n",
    "sample_index_rng_seed : 12640797754436136668\n",
    "schedule_rng_seed : 3135815929913719677\n",
    "accuracy_log_rng_seed : 0\n",
    "accuracy_log_probability : 0\n",
    "accuracy_log_sampling_target : 0\n",
    "print_timestamps : false\n",
    "performance_issue_unique : false\n",
    "performance_issue_same : false\n",
    "performance_issue_same_index : 0\n",
    "performance_sample_count : 2048\n",
    "\n",
    "No warnings encountered during test.\n",
    "\n",
    "No errors encountered during test.\n",
    "Finished running actual test.\n",
    "Device Device:0 processed:\n",
    "  29106 batches of size 1\n",
    "  Memcpy Calls: 0\n",
    "  PerSampleCudaMemcpy Calls: 0\n",
    "  BatchedCudaMemcpy Calls: 29106\n",
    "&&&& PASSED Default_Harness # ./build/bin/harness_default\n",
    "[2021-01-29 23:25:15,883 main.py:341 INFO] Result: 90th percentile latency (ns) : 2078719 and Result is : VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    resnet50: 90th percentile latency (ns) : 2078719 and Result is : VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    resnet50: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    1m16.374s\n",
    "user    1m6.484s\n",
    "sys     0m5.004s\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_singlestream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/resnet50/SingleStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "accuracy=76.064%, good=38032, total=50000\n",
    "hash=7458cd3f1154670a0d063c87b38d2eba7aa8c1921f2558a46333cfef8d9b4036\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=SingleStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "accuracy=76.078%, good=38039, total=50000\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    resnet50: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    resnet50: Accuracy = 76.078, Threshold = 75.695. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    4m27.773s\n",
    "user    2m9.392s\n",
    "sys     0m11.332s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream\"></a>\n",
    "## MultiStream - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Config](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/configs/resnet50/MultiStream/config.json)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; grep AGX_Xavier /datasets/inference_results_v1.0/closed/NVIDIA/configs/resnet50/MultiStream/config.json -A 14\n",
    "    &quot;<font color=\"#DC322F\"><b>AGX_Xavier</b></font>&quot;: {\n",
    "        &quot;concurrent_multi_stream_samples_per_query&quot;: 96,\n",
    "        &quot;config_ver&quot;: {\n",
    "            &quot;maxq&quot;: {}\n",
    "        },\n",
    "        &quot;dla_batch_size&quot;: 15,\n",
    "        &quot;dla_copy_streams&quot;: 2,\n",
    "        &quot;dla_core&quot;: 0,\n",
    "        &quot;dla_inference_streams&quot;: 4,\n",
    "        &quot;dla_multi_stream_samples_per_query&quot;: 15,\n",
    "        &quot;gpu_batch_size&quot;: 66,\n",
    "        &quot;gpu_copy_streams&quot;: 2,\n",
    "        &quot;gpu_inference_streams&quot;: 4,\n",
    "        &quot;gpu_multi_stream_samples_per_query&quot;: 66\n",
    "    },\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=multistream&quot;\n",
    "...\n",
    "[2021-04-27 20:34:39,925 main.py:112 INFO] Finished building engines for resnet50 benchmark in MultiStream scenario.\n",
    "Time taken to generate engines: 118.26688885688782 seconds\n",
    "\n",
    "real    1m59.516s\n",
    "user    0m35.180s\n",
    "sys     0m15.528s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name resnet50-MultiStream*.plan -exec du -hs {} \\;\n",
    "96M     ./build/engines/AGX_Xavier/resnet50/MultiStream/resnet50-MultiStream-gpu-b66-int8.default.plan\n",
    "29M     ./build/engines/AGX_Xavier/resnet50/MultiStream/resnet50-MultiStream-dla-b15-int8.default.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/resnet50/MultiStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per query : 96\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=MultiStream --test_mode=PerformanceOnly&quot;\n",
    "[2021-04-27 20:38:49,061 main.py:701 INFO] Detected System ID: AGX_Xavier\n",
    "[2021-04-27 20:38:49,062 main.py:529 INFO] Using config files: configs/resnet50/MultiStream/config.json\n",
    "[2021-04-27 20:38:49,063 __init__.py:341 INFO] Parsing config file configs/resnet50/MultiStream/config.json ...\n",
    "[2021-04-27 20:38:49,063 main.py:542 INFO] Processing config \"AGX_Xavier_resnet50_MultiStream\"\n",
    "[2021-04-27 20:38:49,064 main.py:224 INFO] Running harness for resnet50 benchmark in MultiStream scenario...\n",
    "...\n",
    "================================================\n",
    "MLPerf Results Summary\n",
    "================================================\n",
    "SUT name : LWIS_Server\n",
    "Scenario : MultiStream\n",
    "Mode     : PerformanceOnly\n",
    "Samples per query : 96\n",
    "Result is : INVALID\n",
    "  Performance constraints satisfied : NO\n",
    "  Min duration satisfied : Yes\n",
    "  Min queries satisfied : Yes\n",
    "Recommendations:\n",
    " * Reduce samples per query to improve latency.\n",
    "\n",
    "================================================\n",
    "Additional Stats\n",
    "================================================\n",
    "Intervals between each IssueQuery:  \"qps\" : 20, \"ms\" : 50\n",
    "50.00 percentile : 1\n",
    "90.00 percentile : 1\n",
    "95.00 percentile : 1\n",
    "97.00 percentile : 1\n",
    "99.00 percentile : 2\n",
    "99.90 percentile : 2\n",
    "\n",
    "Per-query latency:  \"target_ns\" : 50000000, \"target_ms\" : 50\n",
    "50.00 percentile latency (ns)   : 48702492\n",
    "90.00 percentile latency (ns)   : 49325203\n",
    "95.00 percentile latency (ns)   : 49511578\n",
    "97.00 percentile latency (ns)   : 49645776\n",
    "99.00 percentile latency (ns)   : 49978295\n",
    "99.90 percentile latency (ns)   : 50705066\n",
    "\n",
    "Per-sample latency:\n",
    "Min latency (ns)                : 45861628\n",
    "Max latency (ns)                : 182167011\n",
    "Mean latency (ns)               : 48390461\n",
    "50.00 percentile latency (ns)   : 48353859\n",
    "90.00 percentile latency (ns)   : 49233149\n",
    "95.00 percentile latency (ns)   : 49415884\n",
    "97.00 percentile latency (ns)   : 49546249\n",
    "99.00 percentile latency (ns)   : 49851112\n",
    "99.90 percentile latency (ns)   : 50605105\n",
    "\n",
    "================================================\n",
    "Test Parameters Used\n",
    "================================================\n",
    "samples_per_query : 96\n",
    "target_qps : 20\n",
    "target_latency (ns): 50000000\n",
    "max_async_queries : 1\n",
    "min_duration (ms): 600000\n",
    "max_duration (ms): 0\n",
    "min_query_count : 270336\n",
    "max_query_count : 0\n",
    "qsl_rng_seed : 7322528924094909334\n",
    "sample_index_rng_seed : 1570999273408051088\n",
    "schedule_rng_seed : 3507442325620259414\n",
    "accuracy_log_rng_seed : 0\n",
    "accuracy_log_probability : 0\n",
    "accuracy_log_sampling_target : 0\n",
    "print_timestamps : 0\n",
    "performance_issue_unique : 0\n",
    "performance_issue_same : 0\n",
    "performance_issue_same_index : 0\n",
    "performance_sample_count : 2048\n",
    "\n",
    "No warnings encountered during test.\n",
    "\n",
    "No errors encountered during test.\n",
    "...\n",
    "[2021-04-28 10:17:24,243 main.py:280 INFO] Result: requested_multi_stream_samples_per_query: 96, Result is INVALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    resnet50: requested_multi_stream_samples_per_query: 96, Result is INVALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    resnet50: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    228m2.179s\n",
    "user    12m59.700s\n",
    "sys     3m27.784s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resnet50_multistream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/resnet50/MultiStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "accuracy=76.008%, good=38004, total=50000\n",
    "hash=12988c6c56d7af58b5e816d9b9d64b20f5ae80497e355dc51653ed2433b583bb\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=MultiStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "accuracy=76.020%, good=38010, total=50000\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    resnet50: requested_multi_stream_samples_per_query: 96, Result validity unknown\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    resnet50: Accuracy = 76.020, Threshold = 75.695. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    1m2.343s\n",
    "user    0m24.100s\n",
    "sys     0m7.468s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert\"></a>\n",
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline\"></a>\n",
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; make generate_engines RUN_ARGS=&quot;--benchmarks=bert --scenarios=offline&quot;\n",
    "...\n",
    "Time taken to generate engines: 4379.266929149628 seconds\n",
    "\n",
    "real    73m3.881s\n",
    "user    0m32.668s\n",
    "sys     16m22.002s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name bert-Offline*.plan -exec du -hs {} \\;\n",
    "355M    ./build/engines/Orin/bert/Offline/bert-Offline-gpu-int8_S_384_B_256_P_1_vs_il.custom_k_99_MaxP.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/bert-99/Offline/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per second: 476.344\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment (after system reboot!)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; \n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=bert --scenarios=offline --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "\n",
    "[2022-05-23 02:00:20,632 main.py:304 INFO] Result: result_samples_per_second: 482.61, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-Offline:\n",
    "    bert: result_samples_per_second: 482.61, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-Offline:\n",
    "    bert: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    11m18.494s\n",
    "user    0m9.500s\n",
    "sys     0m2.521s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"bert_offline_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v2.0/blob/master/closed/NVIDIA/results/Orin_TRT/bert-99/Offline/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    "{\"exact_match\": 82.687, \"f1\": 90.104}\n",
    "hash=f56718adf61873042f22ce72c152f015b8ac1057a658676ba39c505c2b6f22cf\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>katya@orin</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v2.0/closed/NVIDIA</b></font>&dollar; \n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=resnet50 --scenarios=offline --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "Orin_TRT-custom_k_99_MaxP-Offline:\n",
    "    bert: Accuracy = 90.104, Threshold = 89.965. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    1m54.490s\n",
    "user    1m17.205s\n",
    "sys     0m1.996s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34\"></a>\n",
    "# SSD-ResNet34 - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline\"></a>\n",
    "## Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Config](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/configs/ssd-resnet34/Offline/config.json)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; grep AGX_Xavier /datasets/inference_results_v1.0/closed/NVIDIA/configs/ssd-resnet34/Offline/config.json -A 16\n",
    "    &quot;<font color=\"#DC322F\"><b>AGX_Xavier</b></font>&quot;: {\n",
    "        &quot;concurrent_offline_expected_qps&quot;: 56,\n",
    "        &quot;config_ver&quot;: {\n",
    "            &quot;maxq&quot;: {\n",
    "                &quot;concurrent_offline_expected_qps&quot;: 42\n",
    "            }\n",
    "        },\n",
    "        &quot;dla_batch_size&quot;: 1,\n",
    "        &quot;dla_copy_streams&quot;: 1,\n",
    "        &quot;dla_core&quot;: 0,\n",
    "        &quot;dla_inference_streams&quot;: 1,\n",
    "        &quot;dla_offline_expected_qps&quot;: 10,\n",
    "        &quot;gpu_batch_size&quot;: 2,\n",
    "        &quot;gpu_copy_streams&quot;: 4,\n",
    "        &quot;gpu_inference_streams&quot;: 1,\n",
    "        &quot;gpu_offline_expected_qps&quot;: 35.1243\n",
    "    },\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=offline&quot;\n",
    "...\n",
    "[2021-04-28 21:32:57,015 main.py:112 INFO] Finished building engines for ssd-resnet34 benchmark in Offline scenario.\n",
    "Time taken to generate engines: 381.31431436538696 seconds\n",
    "\n",
    "real    6m23.144s\n",
    "user    2m16.348s\n",
    "sys     0m46.172s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-resnet34-Offline*.plan -exec du -hs {} \\;\n",
    "147M    ./build/engines/AGX_Xavier/ssd-resnet34/Offline/ssd-resnet34-Offline-gpu-b2-int8.default.plan\n",
    "23M     ./build/engines/AGX_Xavier/ssd-resnet34/Offline/ssd-resnet34-Offline-dla-b1-int8.default.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/ssd-resnet34/Offline/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per second: 56.6721\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=Offline --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "================================================\n",
    "MLPerf Results Summary\n",
    "================================================\n",
    "SUT name : LWIS_Server\n",
    "Scenario : Offline\n",
    "Mode     : PerformanceOnly\n",
    "Samples per second: 51.1607\n",
    "Result is : VALID\n",
    "  Min duration satisfied : Yes\n",
    "  Min queries satisfied : Yes\n",
    "\n",
    "================================================\n",
    "Additional Stats\n",
    "================================================\n",
    "Min latency (ns)                : 195940306\n",
    "Max latency (ns)                : 722430107208\n",
    "Mean latency (ns)               : 361257062980\n",
    "50.00 percentile latency (ns)   : 361271790879\n",
    "90.00 percentile latency (ns)   : 650292988467\n",
    "95.00 percentile latency (ns)   : 686348820151\n",
    "97.00 percentile latency (ns)   : 700764011699\n",
    "99.00 percentile latency (ns)   : 715213570646\n",
    "99.90 percentile latency (ns)   : 721724962037\n",
    "\n",
    "================================================\n",
    "Test Parameters Used\n",
    "================================================\n",
    "samples_per_query : 36960\n",
    "target_qps : 56\n",
    "target_latency (ns): 0\n",
    "max_async_queries : 1\n",
    "min_duration (ms): 600000\n",
    "max_duration (ms): 0\n",
    "min_query_count : 1\n",
    "max_query_count : 0\n",
    "qsl_rng_seed : 7322528924094909334\n",
    "sample_index_rng_seed : 1570999273408051088\n",
    "schedule_rng_seed : 3507442325620259414\n",
    "accuracy_log_rng_seed : 0\n",
    "accuracy_log_probability : 0\n",
    "accuracy_log_sampling_target : 0\n",
    "print_timestamps : 0\n",
    "performance_issue_unique : 0\n",
    "performance_issue_same : 0\n",
    "performance_issue_same_index : 0\n",
    "performance_sample_count : 64\n",
    "\n",
    "No warnings encountered during test.\n",
    "\n",
    "No errors encountered during test.\n",
    "...\n",
    "[2021-04-28 21:49:22,497 main.py:280 INFO] Result: result_samples_per_second: 51.1607, Result is VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-Offline:\n",
    "    ssd-resnet34: result_samples_per_second: 51.1607, Result is VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-Offline:\n",
    "    ssd-resnet34: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    12m18.608s\n",
    "user    12m4.692s\n",
    "sys     0m8.680s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_offline_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/ssd-resnet34/Offline/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.237\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.429\n",
    "mAP=20.052%\n",
    "hash=74f272c16708cc31a2c487a16086c6d6a03b121cf34156f94b036c4fad0ad7ac\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=Offline --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.380\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
    "mAP=20.031%\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-Offline:\n",
    "    ssd-resnet34: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-Offline:\n",
    "    ssd-resnet34: Accuracy = 20.031, Threshold = 19.800. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    10m50.156s\n",
    "user    6m3.140s\n",
    "sys     0m23.652s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream\"></a>\n",
    "## SingleStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Config](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/configs/ssd-resnet34/SingleStream/config.json)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; grep AGX_Xavier /datasets/inference_results_v1.0/closed/NVIDIA/configs/ssd-resnet34/SingleStream/config.json -A 11\n",
    "    &quot;<font color=\"#DC322F\"><b>AGX_Xavier</b></font>&quot;: {\n",
    "        &quot;gpu_batch_size&quot;: 1,\n",
    "        &quot;gpu_copy_streams&quot;: 1,\n",
    "        &quot;gpu_inference_streams&quot;: 1,\n",
    "        &quot;gpu_single_stream_expected_latency_ns&quot;: 29478000,\n",
    "        &quot;input_dtype&quot;: &quot;int8&quot;,\n",
    "        &quot;input_format&quot;: &quot;linear&quot;,\n",
    "        &quot;map_path&quot;: &quot;data_maps/coco/val_map.txt&quot;,\n",
    "        &quot;precision&quot;: &quot;int8&quot;,\n",
    "        &quot;tensor_path&quot;: &quot;${PREPROCESSED_DATA_DIR}/coco/val2017/SSDResNet34/int8_linear&quot;,\n",
    "        &quot;use_graphs&quot;: false\n",
    "    },\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=singlestream&quot;\n",
    "...\n",
    "[2021-01-29 17:45:05,185 main.py:153 INFO] Finished building engines for ssd-resnet34 benchmark in SingleStream scenario.\n",
    "Time taken to generate engines: 63.35827445983887 seconds\n",
    "\n",
    "real    1m5.118s\n",
    "user    0m15.400s\n",
    "sys     0m5.076s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-resnet34-SingleStream*.plan -exec du -hs {} \\;\n",
    "37M     ./build/engines/AGX_Xavier/ssd-resnet34/SingleStream/ssd-resnet34-SingleStream-gpu-b1-int8.default.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/ssd-resnet34/SingleStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "90th percentile latency (ns) : 28531845\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=SingleStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "================================================\n",
    "MLPerf Results Summary\n",
    "================================================\n",
    "SUT name : LWIS_Server\n",
    "Scenario : Single Stream\n",
    "Mode     : Performance\n",
    "90th percentile latency (ns) : 28554901\n",
    "Result is : VALID\n",
    "  Min duration satisfied : Yes\n",
    "  Min queries satisfied : Yes\n",
    "\n",
    "================================================\n",
    "Additional Stats\n",
    "================================================\n",
    "QPS w/ loadgen overhead   : 35.17\n",
    "QPS w/o loadgen overhead  : 35.23\n",
    "\n",
    "Min latency (ns)    : 28109905\n",
    "Max latency (ns)    : 32556991\n",
    "Mean latency (ns)   : 28385289\n",
    "50.00 percentile latency (ns)   : 28361924\n",
    "90.00 percentile latency (ns)   : 28554901\n",
    "95.00 percentile latency (ns)   : 28625392\n",
    "97.00 percentile latency (ns)   : 28688816\n",
    "99.00 percentile latency (ns)   : 28884610\n",
    "99.90 percentile latency (ns)   : 29821107\n",
    "\n",
    "================================================\n",
    "Test Parameters Used\n",
    "================================================\n",
    "samples_per_query : 1\n",
    "target_qps : 33.9236\n",
    "target_latency (ns): 0\n",
    "max_async_queries : 1\n",
    "min_duration (ms): 60000\n",
    "max_duration (ms): 0\n",
    "min_query_count : 1024\n",
    "max_query_count : 0\n",
    "qsl_rng_seed : 12786827339337101903\n",
    "sample_index_rng_seed : 12640797754436136668\n",
    "schedule_rng_seed : 3135815929913719677\n",
    "accuracy_log_rng_seed : 0\n",
    "accuracy_log_probability : 0\n",
    "accuracy_log_sampling_target : 0\n",
    "print_timestamps : false\n",
    "performance_issue_unique : false\n",
    "performance_issue_same : false\n",
    "performance_issue_same_index : 0\n",
    "performance_sample_count : 64\n",
    "\n",
    "No warnings encountered during test.\n",
    "\n",
    "No errors encountered during test.\n",
    "Finished running actual test.\n",
    "Device Device:0 processed:\n",
    "  2111 batches of size 1\n",
    "  Memcpy Calls: 0\n",
    "  PerSampleCudaMemcpy Calls: 0\n",
    "  BatchedCudaMemcpy Calls: 2111\n",
    "&&&& PASSED Default_Harness # ./build/bin/harness_default\n",
    "[2021-01-29 22:39:22,362 main.py:341 INFO] Result: 90th percentile latency (ns) : 28554901 and Result is : VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    ssd-resnet34: 90th percentile latency (ns) : 28554901 and Result is : VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    ssd-resnet34: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    1m9.437s\n",
    "user    1m4.720s\n",
    "sys     0m3.964s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_singlestream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/ssd-resnet34/SingleStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
    "mAP=20.111%\n",
    "hash=526aac286ebb67218a3528397b4aecbff9269cbe01307069569345d9c3fbb445\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=SingleStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
    "mAP=20.111%\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    ssd-resnet34: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-SingleStream:\n",
    "    ssd-resnet34: Accuracy = 20.111, Threshold = 19.800. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    12m55.238s\n",
    "user    8m38.988s\n",
    "sys     0m16.408s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream\"></a>\n",
    "## MultiStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Config](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/configs/ssd-resnet34/MultiStream/config.json)\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; grep AGX_Xavier /datasets/inference_results_v1.0/closed/NVIDIA/configs/ssd-resnet34/MultiStream/config.json -A 9\n",
    "    &quot;<font color=\"#DC322F\"><b>AGX_Xavier</b></font>&quot;: {\n",
    "        &quot;gpu_batch_size&quot;: 2,\n",
    "        &quot;gpu_multi_stream_samples_per_query&quot;: 2,\n",
    "        &quot;input_dtype&quot;: &quot;int8&quot;,\n",
    "        &quot;input_format&quot;: &quot;linear&quot;,\n",
    "        &quot;map_path&quot;: &quot;data_maps/coco/val_map.txt&quot;,\n",
    "        &quot;precision&quot;: &quot;int8&quot;,\n",
    "        &quot;tensor_path&quot;: &quot;${PREPROCESSED_DATA_DIR}/coco/val2017/SSDResNet34/int8_linear&quot;,\n",
    "        &quot;use_graphs&quot;: false\n",
    "    },\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream_build\"></a>\n",
    "### Build\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make generate_engines RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=multistream&quot;\n",
    "...\n",
    "[2021-01-29 07:33:48,592 main.py:153 INFO] Finished building engines for ssd-resnet34 benchmark in MultiStream scenario.\n",
    "Time taken to generate engines: 263.8264467716217 seconds\n",
    "\n",
    "real    4m25.496s\n",
    "user    0m32.000s\n",
    "sys     0m35.784s\n",
    "</pre>\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; find . \\\n",
    "-name ssd-resnet34-MultiStream*.plan -exec du -hs {} \\;\n",
    "148M    ./build/engines/AGX_Xavier/ssd-resnet34/MultiStream/ssd-resnet34-MultiStream-gpu-b2-int8.default.plan\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream_performance\"></a>\n",
    "### Performance\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/ssd-resnet34/MultiStream/performance/run_1/mlperf_log_summary.txt#L7)\n",
    "\n",
    "<pre>\n",
    "Samples per query : 2\n",
    "Result is : VALID\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=MultiStream --test_mode=PerformanceOnly&quot;\n",
    "...\n",
    "================================================\n",
    "MLPerf Results Summary\n",
    "================================================\n",
    "SUT name : LWIS_Server\n",
    "Scenario : Multi Stream\n",
    "Mode     : Performance\n",
    "Samples per query : 2\n",
    "Result is : VALID\n",
    "  Performance constraints satisfied : Yes\n",
    "  Min duration satisfied : Yes\n",
    "  Min queries satisfied : Yes\n",
    "\n",
    "================================================\n",
    "Additional Stats\n",
    "================================================\n",
    "Intervals between each IssueQuery:  \"qps\" : 15, \"ms\" : 66.6667\n",
    "50.00 percentile : 1\n",
    "90.00 percentile : 1\n",
    "95.00 percentile : 1\n",
    "97.00 percentile : 1\n",
    "99.00 percentile : 1\n",
    "99.90 percentile : 1\n",
    "\n",
    "Per-query latency:  \"target_ns\" : 66666666, \"target_ms\" : 66.6667\n",
    "50.00 percentile latency (ns)   : 55624812\n",
    "90.00 percentile latency (ns)   : 55913099\n",
    "95.00 percentile latency (ns)   : 56006924\n",
    "97.00 percentile latency (ns)   : 56067621\n",
    "99.00 percentile latency (ns)   : 56189283\n",
    "99.90 percentile latency (ns)   : 56401684\n",
    "\n",
    "Per-sample latency:\n",
    "Min latency (ns)                : 55180175\n",
    "Max latency (ns)                : 61310689\n",
    "Mean latency (ns)               : 55646311\n",
    "50.00 percentile latency (ns)   : 55624812\n",
    "90.00 percentile latency (ns)   : 55913099\n",
    "95.00 percentile latency (ns)   : 56006924\n",
    "97.00 percentile latency (ns)   : 56067621\n",
    "99.00 percentile latency (ns)   : 56189283\n",
    "99.90 percentile latency (ns)   : 56401684\n",
    "\n",
    "================================================\n",
    "Test Parameters Used\n",
    "================================================\n",
    "samples_per_query : 2\n",
    "target_qps : 15\n",
    "target_latency (ns): 66666666\n",
    "max_async_queries : 1\n",
    "min_duration (ms): 60000\n",
    "max_duration (ms): 0\n",
    "min_query_count : 270336\n",
    "max_query_count : 0\n",
    "qsl_rng_seed : 12786827339337101903\n",
    "sample_index_rng_seed : 12640797754436136668\n",
    "schedule_rng_seed : 3135815929913719677\n",
    "accuracy_log_rng_seed : 0\n",
    "accuracy_log_probability : 0\n",
    "accuracy_log_sampling_target : 0\n",
    "print_timestamps : false\n",
    "performance_issue_unique : false\n",
    "performance_issue_same : false\n",
    "performance_issue_same_index : 0\n",
    "performance_sample_count : 64\n",
    "\n",
    "No warnings encountered during test.\n",
    "\n",
    "No errors encountered during test.\n",
    "Finished running actual test.\n",
    "Equivalent QPS computed by samples_per_query*target_qps : 30\n",
    "Device Device:0 processed:\n",
    "  270336 batches of size 2\n",
    "  Memcpy Calls: 0\n",
    "  PerSampleCudaMemcpy Calls: 0\n",
    "  BatchedCudaMemcpy Calls: 270336\n",
    "&&&& PASSED Default_Harness # ./build/bin/harness_default\n",
    "[2021-01-29 13:12:12,503 main.py:341 INFO] Result: Samples per query : 2 and Result is : VALID\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    ssd-resnet34: Samples per query : 2 and Result is : VALID\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    ssd-resnet34: No accuracy results in PerformanceOnly mode.\n",
    "\n",
    "\n",
    "real    300m37.676s\n",
    "user    5m11.760s\n",
    "sys     0m27.856s\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ssd-resnet34_multistream_accuracy\"></a>\n",
    "### Accuracy\n",
    "\n",
    "#### [Submitted experiment](https://github.com/mlcommons/inference_results_v1.0/blob/master/closed/NVIDIA/results/AGX_Xavier_TRT/ssd-resnet34/MultiStream/accuracy/accuracy.txt)\n",
    "\n",
    "<pre>\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
    "mAP=20.111%\n",
    "hash=859242388c9a94513b189eb58a55bd11ad1d2f7d094880dfb72157a7ac5e45fd\n",
    "</pre>\n",
    "\n",
    "#### Reproduced experiment\n",
    "\n",
    "<pre><font color=\"#859900\"><b>anton@xavier</b></font>:<font color=\"#268BD2\"><b>/datasets/inference_results_v1.0/closed/NVIDIA</b></font>&dollar; time \\\n",
    "MLPERF_SCRATCH_PATH=/datasets/mlperf_scratch_path \\\n",
    "make run_harness RUN_ARGS=&quot;--benchmarks=ssd-resnet34 --scenarios=MultiStream --test_mode=AccuracyOnly&quot;\n",
    "...\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
    "mAP=20.111%\n",
    "\n",
    "======================= Perf harness results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    ssd-resnet34: Cannot find performance result. Maybe you are running in AccuracyOnly mode.\n",
    "\n",
    "\n",
    "======================= Accuracy results: =======================\n",
    "\n",
    "AGX_Xavier_TRT-default-MultiStream:\n",
    "    ssd-resnet34: Accuracy = 20.111, Threshold = 19.800. Accuracy test PASSED.\n",
    "\n",
    "\n",
    "real    11m44.285s\n",
    "user    4m22.432s\n",
    "sys     0m17.144s\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
